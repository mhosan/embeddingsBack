# Investigaci√≥n: Modelos de Embeddings Gratuitos en Hugging Face

## ‚úÖ Compatibilidad con InferenceClient

**TODOS los modelos investigados son compatibles con `InferenceClient.feature_extraction()`**

El `InferenceClient` de Hugging Face soporta la tarea de `feature_extraction` (generaci√≥n de embeddings) para todos los modelos mencionados en esta investigaci√≥n:

- ‚úÖ **BAAI/bge-small-en-v1.5** (modelo actual)
- ‚úÖ **sentence-transformers/all-MiniLM-L6-v2**
- ‚úÖ **sentence-transformers/all-mpnet-base-v2**
- ‚úÖ **intfloat/e5-large-v2**
- ‚úÖ **BAAI/bge-base-en-v1.5**
- ‚úÖ **BAAI/bge-m3**

**Uso**: Simplemente cambia el par√°metro `model` en la llamada a `client.feature_extraction()`:

```python
# Ejemplo de cambio de modelo
result = client.feature_extraction(
    text=texts,
    model="sentence-transformers/all-MiniLM-L6-v2"  # Cambiar aqu√≠
)
```

**Nota importante**: Al cambiar de modelo, tambi√©n debes actualizar `MODEL_DIMENSIONS` en `constants.py` para que coincida con las dimensiones del nuevo modelo.

---

## ‚ö†Ô∏è ADVERTENCIA CR√çTICA: Cambio de Dimensiones en Supabase

### Problema con pgvector

**Si cambias a un modelo con dimensiones diferentes (ej: de 384 a 768), HABR√Å PROBLEMAS con la base de datos Supabase.**

La columna `embedding` en tu tabla `documents` est√° definida como `vector(384)` en PostgreSQL/pgvector. Esto significa:

- ‚ùå **NO puedes insertar** vectores de 768 dimensiones en una columna `vector(384)`
- ‚ùå **NO puedes cambiar** las dimensiones de una columna existente con un simple `ALTER COLUMN`
- ‚ùå **Los datos existentes** (embeddings de 384 dimensiones) NO son compatibles con modelos de 768 dimensiones

### Opciones si Quieres Cambiar de Dimensiones

#### **Opci√≥n 1: Crear Nueva Columna y Migrar** (Recomendado)

```sql
-- 1. Agregar nueva columna con las nuevas dimensiones
ALTER TABLE documents ADD COLUMN embedding_768 vector(768);

-- 2. Regenerar embeddings para todos los documentos existentes
-- (esto debe hacerse desde tu aplicaci√≥n Python)

-- 3. Opcional: Eliminar la columna antigua
ALTER TABLE documents DROP COLUMN embedding;

-- 4. Renombrar la nueva columna
ALTER TABLE documents RENAME COLUMN embedding_768 TO embedding;
```

**Implicaciones:**
- ‚úÖ Mantiene los datos existentes
- ‚ö†Ô∏è Requiere **regenerar TODOS los embeddings** con el nuevo modelo
- ‚ö†Ô∏è Puede ser costoso en tiempo si tienes muchos documentos

#### **Opci√≥n 2: Crear Nueva Tabla** (M√°s seguro)

```sql
-- Crear nueva tabla con las nuevas dimensiones
CREATE TABLE documents_v2 (
    id BIGSERIAL PRIMARY KEY,
    content TEXT NOT NULL,
    embedding vector(768),  -- Nueva dimensi√≥n
    metadata JSONB,
    source TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Crear √≠ndice para b√∫squeda vectorial
CREATE INDEX ON documents_v2 USING ivfflat (embedding vector_cosine_ops);
```

**Implicaciones:**
- ‚úÖ Mantiene la tabla original intacta (backup autom√°tico)
- ‚úÖ Puedes comparar resultados entre modelos
- ‚ö†Ô∏è Requiere actualizar el c√≥digo para usar la nueva tabla

#### **Opci√≥n 3: Borrar Todo y Empezar de Cero** (M√°s simple, pero destructivo)

```sql
-- ‚ö†Ô∏è ESTO BORRA TODOS LOS DATOS
DROP TABLE documents;

-- Crear tabla nueva con las nuevas dimensiones
CREATE TABLE documents (
    id BIGSERIAL PRIMARY KEY,
    content TEXT NOT NULL,
    embedding vector(768),  -- Nueva dimensi√≥n
    metadata JSONB,
    source TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX ON documents USING ivfflat (embedding vector_cosine_ops);
```

**Implicaciones:**
- ‚ùå **PIERDES TODOS LOS DATOS EXISTENTES**
- ‚úÖ M√°s simple y r√°pido
- ‚úÖ √ötil si est√°s en fase de pruebas

### Modelos que NO Requieren Cambios en la BD

Estos modelos usan **384 dimensiones** (igual que el actual):

- ‚úÖ **sentence-transformers/all-MiniLM-L6-v2** (384 dims)
- ‚úÖ **BAAI/bge-small-en-v1.5** (384 dims) ‚Üê Modelo actual

**Puedes cambiar entre estos modelos SIN modificar la base de datos.**

### Modelos que S√ç Requieren Cambios en la BD

Estos modelos usan dimensiones diferentes:

- ‚ö†Ô∏è **sentence-transformers/all-mpnet-base-v2** (768 dims)
- ‚ö†Ô∏è **BAAI/bge-base-en-v1.5** (768 dims)
- ‚ö†Ô∏è **intfloat/e5-large-v2** (1024 dims)
- ‚ö†Ô∏è **BAAI/bge-m3** (1024 dims)

**Requieren migraci√≥n de la base de datos antes de usarlos.**

### Recomendaci√≥n

Si quieres probar un modelo con diferentes dimensiones:

1. **Opci√≥n segura**: Usa la **Opci√≥n 2** (nueva tabla) para no perder datos
2. **Opci√≥n r√°pida**: Si est√°s en desarrollo/pruebas, usa la **Opci√≥n 3** (borrar y recrear)
3. **Para producci√≥n**: Usa la **Opci√≥n 1** (migrar columna) con un script de migraci√≥n bien testeado

---

## Modelo Actual
**BAAI/bge-small-en-v1.5**
- **Dimensiones**: 384
- **Par√°metros**: 33.4 millones
- **Tama√±o**: ~134 MB
- **Rendimiento**: Estado del arte en MTEB y C-MTEB benchmarks para su categor√≠a
- **Casos de uso**: B√∫squeda sem√°ntica, clustering, clasificaci√≥n de texto, recuperaci√≥n densa

---

## Alternativas Gratuitas en Hugging Face

### 1. **sentence-transformers/all-MiniLM-L6-v2** ‚ö° (M√ÅS R√ÅPIDO)

| Caracter√≠stica | Valor |
|----------------|-------|
| **Dimensiones** | 384 |
| **Par√°metros** | 22 millones |
| **Tama√±o** | ~22 MB |
| **Velocidad** | ~14,200 oraciones/segundo (CPU) |
| **Latencia** | 14.7 ms por 1K tokens |

**Ventajas:**
- ‚úÖ **5x m√°s r√°pido** que modelos como all-mpnet-base-v2
- ‚úÖ **M√°s liviano** (22M vs 33.4M par√°metros)
- ‚úÖ Excelente para aplicaciones de alta demanda y baja latencia
- ‚úÖ Ideal para APIs en tiempo real y chatbots

**Desventajas:**
- ‚ö†Ô∏è Precisi√≥n de recuperaci√≥n **5-8% menor** que modelos m√°s grandes
- ‚ö†Ô∏è Optimizado para textos cortos (128-256 tokens)
- ‚ö†Ô∏è Rendimiento puede degradarse con documentos largos o ruidosos

**Comparaci√≥n con bge-small-en-v1.5:**
- üî¥ **Menos preciso** en tareas de recuperaci√≥n y clasificaci√≥n
- üü¢ **M√°s r√°pido** en inferencia
- üü¢ **M√°s liviano** en memoria

---

### 2. **sentence-transformers/all-mpnet-base-v2** üéØ (EQUILIBRADO)

| Caracter√≠stica | Valor |
|----------------|-------|
| **Dimensiones** | 768 |
| **Par√°metros** | ~110 millones |
| **Tama√±o** | ~420 MB |

**Ventajas:**
- ‚úÖ Rendimiento s√≥lido en tareas de similitud de texto
- ‚úÖ Ampliamente usado y probado en producci√≥n
- ‚úÖ Mayor dimensionalidad (768 vs 384)

**Desventajas:**
- ‚ö†Ô∏è **M√°s lento** que all-MiniLM-L6-v2
- ‚ö†Ô∏è **M√°s pesado** (110M vs 33.4M par√°metros)
- ‚ö†Ô∏è Generalmente **superado por BGE** en benchmarks MTEB

**Comparaci√≥n con bge-small-en-v1.5:**
- üî¥ **Menos preciso** en MTEB
- üî¥ **M√°s pesado** (3.3x m√°s par√°metros)
- üü° Dimensiones m√°s altas (768 vs 384)

---

### 3. **intfloat/e5-large-v2** üí™ (M√ÅS POTENTE - pero m√°s pesado)

| Caracter√≠stica | Valor |
|----------------|-------|
| **Dimensiones** | 1024 |
| **Par√°metros** | ~335 millones |
| **Tama√±o** | ~1.34 GB |

**Ventajas:**
- ‚úÖ **Mejor rendimiento** que all-mpnet-base-v2
- ‚úÖ Optimizado para m√∫ltiples idiomas
- ‚úÖ Alta dimensionalidad (1024)

**Desventajas:**
- ‚ö†Ô∏è **Mucho m√°s lento** debido al tama√±o
- ‚ö†Ô∏è **10x m√°s pesado** que bge-small-en-v1.5
- ‚ö†Ô∏è Mayor consumo de recursos

**Comparaci√≥n con bge-small-en-v1.5:**
- üü¢ **M√°s preciso** en benchmarks
- üî¥ **Mucho m√°s lento** y pesado
- üî¥ **10x m√°s par√°metros** (335M vs 33.4M)

---

### 4. **BAAI/bge-base-en-v1.5** üìà (VERSI√ìN MEJORADA DEL MISMO MODELO)

| Caracter√≠stica | Valor |
|----------------|-------|
| **Dimensiones** | 768 |
| **Par√°metros** | ~109 millones |
| **Tama√±o** | ~438 MB |

**Ventajas:**
- ‚úÖ **Mejor rendimiento** que bge-small-en-v1.5
- ‚úÖ Misma familia BGE (f√°cil migraci√≥n)
- ‚úÖ Mayor dimensionalidad (768 vs 384)
- ‚úÖ Excelente en MTEB leaderboard

**Desventajas:**
- ‚ö†Ô∏è **3.3x m√°s pesado** que bge-small
- ‚ö†Ô∏è M√°s lento en inferencia

**Comparaci√≥n con bge-small-en-v1.5:**
- üü¢ **M√°s preciso** (versi√≥n base del mismo modelo)
- üî¥ **M√°s pesado** (109M vs 33.4M par√°metros)
- üü° Mayor dimensionalidad requiere m√°s espacio en BD

---

### 5. **BAAI/bge-m3** üåç (MULTILING√úE Y MULTIFUNCIONAL)

| Caracter√≠stica | Valor |
|----------------|-------|
| **Dimensiones** | 1024 |
| **Par√°metros** | ~567 millones |
| **Idiomas** | 100+ |
| **Tokens m√°ximos** | 8192 |

**Ventajas:**
- ‚úÖ **Multiling√ºe** (100+ idiomas)
- ‚úÖ **Multi-granularidad** (hasta 8192 tokens)
- ‚úÖ **Multi-funcional** (recuperaci√≥n densa, l√©xica, multi-vector)
- ‚úÖ Muy vers√°til para escenarios complejos

**Desventajas:**
- ‚ö†Ô∏è **Muy pesado** (567M par√°metros)
- ‚ö†Ô∏è Overkill si solo necesitas ingl√©s
- ‚ö†Ô∏è Mucho m√°s lento

**Comparaci√≥n con bge-small-en-v1.5:**
- üü¢ **Mucho m√°s potente** y vers√°til
- üî¥ **17x m√°s pesado** (567M vs 33.4M)
- üü° Solo √∫til si necesitas multiling√ºismo

---

## Recomendaciones por Caso de Uso

### ‚úÖ **Mantener BAAI/bge-small-en-v1.5** si:
- Necesitas un **balance √≥ptimo** entre rendimiento y velocidad
- Tu aplicaci√≥n es principalmente en **ingl√©s**
- Quieres **estado del arte** en su categor√≠a de tama√±o
- Tienes recursos limitados pero necesitas buena precisi√≥n

### üîÑ **Cambiar a sentence-transformers/all-MiniLM-L6-v2** si:
- La **velocidad es cr√≠tica** (APIs de alta demanda)
- Puedes sacrificar 5-8% de precisi√≥n por **2-3x m√°s velocidad**
- Necesitas **menor consumo de memoria**
- Trabajas principalmente con textos cortos

### üìà **Upgrade a BAAI/bge-base-en-v1.5** si:
- Necesitas **mejor precisi√≥n** y puedes pagar el costo
- Tienes recursos suficientes (3x m√°s memoria)
- La precisi√≥n es m√°s importante que la velocidad
- Quieres mantener la misma familia BGE

### üåç **Cambiar a BAAI/bge-m3** si:
- Necesitas **soporte multiling√ºe** (100+ idiomas)
- Trabajas con **documentos largos** (hasta 8192 tokens)
- Tienes recursos abundantes
- Necesitas funcionalidad avanzada

---

## Tabla Comparativa Resumida

| Modelo | Dimensiones | Par√°metros | Velocidad | Precisi√≥n | Mejor para |
|--------|-------------|------------|-----------|-----------|------------|
| **bge-small-en-v1.5** ‚≠ê | 384 | 33.4M | Media | Alta | Balance √≥ptimo |
| all-MiniLM-L6-v2 | 384 | 22M | **Muy alta** | Media | Velocidad |
| all-mpnet-base-v2 | 768 | 110M | Baja | Media-Alta | General |
| bge-base-en-v1.5 | 768 | 109M | Baja | **Muy alta** | Precisi√≥n |
| e5-large-v2 | 1024 | 335M | Muy baja | Muy alta | Precisi√≥n m√°xima |
| bge-m3 | 1024 | 567M | Muy baja | Muy alta | Multiling√ºe |

---

## Conclusi√≥n

El modelo actual **BAAI/bge-small-en-v1.5** es una **excelente elecci√≥n** que ofrece:
- ‚úÖ Estado del arte en su categor√≠a de tama√±o
- ‚úÖ Balance √≥ptimo entre velocidad y precisi√≥n
- ‚úÖ Tama√±o razonable (33.4M par√°metros)
- ‚úÖ Rendimiento superior a alternativas populares como all-MiniLM-L6-v2 y all-mpnet-base-v2

### Opciones m√°s potentes:
1. **BAAI/bge-base-en-v1.5** - Mejor precisi√≥n, 3x m√°s pesado
2. **intfloat/e5-large-v2** - A√∫n mejor precisi√≥n, 10x m√°s pesado
3. **BAAI/bge-m3** - M√°xima versatilidad, 17x m√°s pesado

### Opci√≥n m√°s r√°pida (pero menos precisa):
- **sentence-transformers/all-MiniLM-L6-v2** - 2-3x m√°s r√°pido, 5-8% menos preciso

**Recomendaci√≥n final**: Mantener el modelo actual a menos que tengas necesidades espec√≠ficas de velocidad extrema o precisi√≥n m√°xima.
